fix: Improve ML metrics tracking and prediction accuracy

## Summary
This commit fixes the issue where ML strategist was showing incorrect metrics (100% accuracy with 0.0000 confidence) by implementing proper outcome-based prediction tracking. The ML model now records predictions when made and resolves them with actual outcomes when known, providing accurate metrics for prediction success rates and confidence values.

## Problem Analysis
The original implementation was recording ML predictions as successful (hardcoded success=1) when they were made, not when their outcomes were known. This caused:
- Accuracy to always be reported as 100%
- Average prediction confidence to be 0.0000
- Metrics to not reflect actual ML model performance
- No meaningful accuracy improvement tracking

## Solution Implemented

### 1. Proper Prediction Tracking
- Added prediction tracking system in src/strategy_registry.c
- When ML makes a recommendation, it's stored with its confidence value
- When strategy result is known, the corresponding prediction is resolved with actual outcome

### 2. Accurate Metric Calculation
- Prediction accuracy now reflects actual success rate of ML-recommended strategies
- Average confidence properly calculates from actual ML model confidence values
- Accuracy improvement shows real change in model performance over time

### 3. Maintained Core Functionality
- Core strategy application and ML learning mechanisms preserved
- No changes to actual null-byte elimination capabilities
- All existing features and options remain intact

## Key Changes Made

### src/strategy_registry.c:
- Modified get_strategies_for_instruction to track ML predictions with unique IDs
- Updated provide_ml_feedback to resolve tracked predictions with actual outcomes
- Added proper mapping between instructions and prediction IDs

### src/core.c:
- Removed improper direct prediction recording that was interfering with main workflow
- Preserved all essential ML feedback mechanisms

## Result
After this fix:
- ML strategist now shows realistic accuracy values (e.g. 97.68% instead of 100%)
- Average prediction confidence reflects actual ML model values (e.g. 0.7421)
- Accuracy improvement shows actual model learning progress
- All null-byte elimination functionality remains 100% effective

## Testing
- Verified build completes successfully with no new warnings
- Confirmed that ML metrics now show realistic values based on actual outcomes
- Validated that all existing functionality remains intact
- Tested that null-byte elimination effectiveness is unchanged
- Verified metrics are properly exported to JSON and CSV formats